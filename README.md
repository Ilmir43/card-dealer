# Card Dealer

**Внимание!** Вся документация в этом проекте должна быть на русском языке.

Данный репозиторий содержит заготовку системы для распознавания и раздачи игральных карт.

## Структура проекта

```
card_dealer/            # Python-пакет с исходным кодом
    __init__.py
    camera.py           # захват изображений с камеры
    recognizer.py       # простое распознавание карт по шаблонам
    servo_controller.py # управление сервоприводом
    main.py             # пример запуска

dataset/                # изображения карт и временные снимки
generate_embeddings.py  # создание базы эмбеддингов
recognize_card.py       # распознавание карты по эмбеддингам
streamlit_capture.py    # сбор изображений через камеру
validate_crops.py       # проверка качества обрезки
model.py                # архитектура нейронной сети
utils.py                # утилиты сохранения модели
```

## Установка

1. Требуется **Python 3.9** или новее.
2. При необходимости создайте и активируйте виртуальное окружение.
3. Установите зависимости:

```bash
pip install -r requirements.txt
```

Основные зависимости: `opencv-python`, `flask`, `numpy`, `torch` и `torchvision`.
Пакеты `picamera` и `RPi.GPIO` нужны только на Raspberry Pi и
автоматически пропускаются при установке на macOS и других системах.

## Конфигурация камеры

Модуль `card_dealer.camera` предоставляет функцию `capture_image`, снимающую кадр с устройства `0` (обычно `/dev/video0`) в разрешении **320x180**. На macOS с чипом M1 можно передать параметр `api_preference=cv2.CAP_AVFOUNDATION`, чтобы задействовать встроенную камеру. Параметр `camera_settings` позволяет управлять яркостью, контрастом и другими свойствами камеры.
Функция `stream_frames` использует те же параметры и позволяет получать видео для веб‑страницы `/live`. Для записи ролика предусмотрена функция `record_video`.
Функция `find_card` выделяет карту на переданном кадре и возвращает обрезанное изображение либо `None`, если карта не найдена. При просмотре `/live` распознавание выполняется именно по такому кадру.

## Аппаратная часть

### Камера

- Подключите USB‑камеру или камеру Raspberry Pi, чтобы она была доступна как `/dev/video0`.
- При необходимости измените индекс устройства или разрешение в функции `capture_image`.
- На macOS Ventura и iOS 16 можно использовать **Continuity Camera** и задействовать камеру iPhone.
  После подключения iPhone выберите его как источник (обычно устройство с индексом `1`) и,
  при необходимости, передайте `api_preference=cv2.CAP_AVFOUNDATION`.

### Серво

`card_dealer.servo_controller` позволяет управлять сервомотором двумя способами:

1. **GPIO PWM** — укажите номер GPIO‑пина при создании `ServoController`.
2. **Последовательный порт** — укажите имя порта (например, `/dev/ttyUSB0`).
   Для этого режима необходим пакет `pyserial`.

## Запуск примеров

Простейший пример захватывает изображение и пытается определить карту:

```python
from pathlib import Path
from card_dealer.camera import capture_image
import cv2
from card_dealer.recognizer import recognize_card
from card_dealer.camera import find_card

# Для macOS можно указать api_preference=cv2.CAP_AVFOUNDATION
img = capture_image(Path("test.png"), api_preference=cv2.CAP_AVFOUNDATION)
card = find_card(img)
if card is not None:
    cv2.imwrite("card.png", card)
    print("Обнаружена карта:", recognize_card(Path("card.png")))
else:
    print("Карта не найдена")
```

Для выдачи карты сервоприводом на GPIO‑пине `11`:

```python
from card_dealer.servo_controller import ServoController

controller = ServoController(pwm_pin=11)
controller.dispense_card()
controller.cleanup()
```

## Тесты

После установки зависимостей запустите тесты командой:

```bash
pytest
```


## Подготовка базы эмбеддингов

Для распознавания теперь используется ResNet18 в роли извлекателя признаков.
Сначала сформируйте базу эмбеддингов для всех изображений в каталоге `datasets`:

```bash
python generate_embeddings.py --data datasets --output embeddings.pkl
```

Файл `embeddings.pkl` содержит путь к каждому изображению, метку класса и
вектор признаков (512 значений). Базу можно расширять, просто добавляя новые
изображения в каталог `datasets` и заново запуская скрипт.

## Распознавание карты

Когда база готова, определите карту на изображении командой:

```bash
python recognize_card.py path/to/card.jpg --embeddings embeddings.pkl
```

Скрипт выводит несколько наиболее похожих вариантов с косинусной схожестью.


## Конвертация форматов моделей

В случае необходимости можно преобразовывать веса между форматом Keras (`.h5`)
и файлом PyTorch (`.pt`). В репозитории для этого имеется скрипт
`convert_model.py`.

Примеры использования:

```bash
# h5 -> pt
python convert_model.py keras_model.h5 model.pt

# pt -> h5
python convert_model.py model.pt keras_model.h5 --reverse
```

Скрипт предполагает, что архитектура модели одинакова в обоих фреймворках
(в проекте это ResNet18).


## Конвертация датасета для YOLOv8

Скрипт `convert_dataset_to_yolo.py` преобразует `cards.csv` в структуру `datasets/cards` для обучения детектора. При необходимости его можно
применить к собранным снимкам.
Каждый снимок копируется и получает разметку на весь кадр.

```bash
python convert_dataset_to_yolo.py cards.csv datasets/cards
```


## Демонстрация

Файл `streamlit_app.py` предоставляет простой интерфейс Streamlit.
Запустите его командой:

```bash
streamlit run streamlit_app.py
```

В боковой панели можно выбрать распознавание по обученной модели
или по базе эмбеддингов. Модели с расширением `.pt` ищутся во всём проекте,
поэтому их не обязательно помещать в отдельную папку.
Укажите путь к файлу `embeddings.pkl` или модели и загрузите изображение либо
видео.  Приложение покажет предполагаемые карты в порядке появления.

## Сбор изображений

Для пополнения базы снимков предназначен скрипт `streamlit_capture.py`. Он
позволяет делать фотографии с камеры прямо из браузера.

```bash
streamlit run streamlit_capture.py
```

Укажите игру, название карты и дополнительные параметры. Снимки сохраняются в
каталог `datasets/<игра>/<карта>/` вместе с метаданными и обрезанной версией.

На macOS Ventura и iOS 16 или новее можно воспользоваться **Continuity Camera**.
При открытом приложении Streamlit разрешите доступ к камере в браузере и
выберите iPhone в списке устройств. Компонент `st.camera_input` будет передавать
изображение с телефона без дополнительной настройки.
